{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d17b093d-7142-4005-837d-67224a77fe93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement huggingfac_hub (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[31mERROR: No matching distribution found for huggingfac_hub\u001b[0m\u001b[31m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install huggingfac_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9400bbc1-8ee1-4361-a3f5-5185abc4a354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Modified version without tqdm.notebook dependency\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm  # Using regular tqdm instead of notebook version\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class HuggingFaceScraper:\n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://huggingface.co\"\n",
    "        self.api_url = \"https://huggingface.co/api/models\"\n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "        }\n",
    "        self.models_data = []\n",
    "    \n",
    "    # [Rest of the class methods remain the same]\n",
    "    def get_popular_model_families(self):\n",
    "        \"\"\"Returns list of popular model families to search for\"\"\"\n",
    "        return [\n",
    "            # Large language models\n",
    "            \"gpt\", \"llama\", \"mistral\", \"falcon\",\n",
    "            # Encoders/BERT-like models\n",
    "            \"bert\", \"roberta\", \n",
    "            # Vision models\n",
    "            \"vit\", \"clip\", \"resnet\", \n",
    "            # Audio models\n",
    "            \"whisper\"\n",
    "        ]\n",
    "    \n",
    "    def get_models_by_family(self, family, limit=20):\n",
    "        \"\"\"Get popular models for a specific family\"\"\"\n",
    "        params = {\n",
    "            \"search\": family,\n",
    "            \"sort\": \"downloads\",\n",
    "            \"direction\": \"-1\",\n",
    "            \"limit\": str(limit)\n",
    "        }\n",
    "        \n",
    "        response = requests.get(self.api_url, params=params, headers=self.headers)\n",
    "        if response.status_code == 200:\n",
    "            models = response.json()\n",
    "            print(f\"Found {len(models)} models for family {family}\")\n",
    "            return models\n",
    "        else:\n",
    "            print(f\"Error getting models for family {family}: {response.status_code}\")\n",
    "            return []\n",
    "    \n",
    "    def get_model_details(self, model_id):\n",
    "        \"\"\"Get detailed information about a specific model\"\"\"\n",
    "        api_url = f\"{self.api_url}/{model_id}\"\n",
    "        response = requests.get(api_url, headers=self.headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Error fetching details for {model_id}: {response.status_code}\")\n",
    "            return None\n",
    "    \n",
    "    def extract_parameters(self, model_info, model_id):\n",
    "        \"\"\"Extract parameter count from model info\"\"\"\n",
    "        # Try to get from card data first\n",
    "        if model_info and \"cardData\" in model_info and model_info[\"cardData\"]:\n",
    "            card_data = model_info[\"cardData\"]\n",
    "            if \"model-index\" in card_data and len(card_data[\"model-index\"]) > 0:\n",
    "                params = card_data[\"model-index\"][0].get(\"parameters\")\n",
    "                if params:\n",
    "                    return params\n",
    "        \n",
    "        # If not found, try to scrape from model page\n",
    "        model_url = f\"{self.base_url}/{model_id}\"\n",
    "        response = requests.get(model_url, headers=self.headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            readme = soup.select_one('.prose') or soup.select_one('.markdown')\n",
    "            \n",
    "            if readme:\n",
    "                text = readme.get_text()\n",
    "                \n",
    "                # Various patterns for parameter counts\n",
    "                param_patterns = [\n",
    "                    r'(\\d+(\\.\\d+)?)\\s*[Bb](illion)?\\s*parameters',\n",
    "                    r'(\\d+(\\.\\d+)?)\\s*[Mm](illion)?\\s*parameters',\n",
    "                    r'(\\d+(\\.\\d+)?)\\s*billion\\s*parameters',\n",
    "                    r'(\\d+(\\.\\d+)?)\\s*million\\s*parameters',\n",
    "                    r'(\\d+(\\.\\d+)?)\\s*[BbMm]\\s*params',\n",
    "                    r'parameters:\\s*(\\d+(\\.\\d+)?)\\s*[BbMm]',\n",
    "                ]\n",
    "                \n",
    "                for pattern in param_patterns:\n",
    "                    match = re.search(pattern, text, re.IGNORECASE)\n",
    "                    if match:\n",
    "                        value = float(match.group(1))\n",
    "                        if 'billion' in pattern.lower() or 'b' in pattern.lower():\n",
    "                            value *= 1_000_000_000\n",
    "                        elif 'million' in pattern.lower() or 'm' in pattern.lower():\n",
    "                            value *= 1_000_000\n",
    "                        \n",
    "                        return int(value)\n",
    "        \n",
    "        # Try to infer from model name as last resort\n",
    "        model_id_lower = model_id.lower()\n",
    "        if 'gpt2-xl' in model_id_lower:\n",
    "            return 1_500_000_000\n",
    "        elif 'gpt2-large' in model_id_lower:\n",
    "            return 774_000_000\n",
    "        elif 'gpt2-medium' in model_id_lower:\n",
    "            return 355_000_000\n",
    "        elif 'gpt2' in model_id_lower:\n",
    "            return 124_000_000\n",
    "        elif 'bert-base' in model_id_lower:\n",
    "            return 110_000_000\n",
    "        elif 'bert-large' in model_id_lower:\n",
    "            return 340_000_000\n",
    "            \n",
    "        return None\n",
    "    \n",
    "    def extract_metrics(self, model_info):\n",
    "        \"\"\"Extract performance metrics from model info\"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        if not model_info or \"cardData\" not in model_info or not model_info[\"cardData\"]:\n",
    "            return metrics\n",
    "        \n",
    "        card_data = model_info[\"cardData\"]\n",
    "        \n",
    "        # Try to get from model-index structure\n",
    "        if \"model-index\" in card_data and len(card_data[\"model-index\"]) > 0:\n",
    "            model_index = card_data[\"model-index\"][0]\n",
    "            \n",
    "            # Get results/metrics\n",
    "            results = model_index.get(\"results\", [])\n",
    "            for result in results:\n",
    "                task_info = result.get(\"task\", {})\n",
    "                task_type = task_info.get(\"type\", \"unknown\")\n",
    "                dataset = task_info.get(\"dataset\", {}).get(\"name\", \"unknown\")\n",
    "                \n",
    "                for metric in result.get(\"metrics\", []):\n",
    "                    metric_name = metric.get(\"type\", \"\")\n",
    "                    metric_value = metric.get(\"value\")\n",
    "                    \n",
    "                    if metric_name and metric_value is not None:\n",
    "                        key = f\"{task_type}_{dataset}_{metric_name}\"\n",
    "                        metrics[key] = metric_value\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def scrape_models(self, max_models=100):\n",
    "        \"\"\"Main method to scrape models\"\"\"\n",
    "        # Get models by family\n",
    "        all_models = []\n",
    "        \n",
    "        for family in self.get_popular_model_families():\n",
    "            family_models = self.get_models_by_family(family, limit=20)\n",
    "            all_models.extend(family_models)\n",
    "            time.sleep(0.5)  # Be nice to the API\n",
    "        \n",
    "        # Remove duplicates and limit\n",
    "        unique_models = []\n",
    "        seen_ids = set()\n",
    "        \n",
    "        for model in all_models:\n",
    "            if model['id'] not in seen_ids:\n",
    "                seen_ids.add(model['id'])\n",
    "                unique_models.append(model)\n",
    "        \n",
    "        models_to_scrape = unique_models[:max_models]\n",
    "        print(f\"Will scrape details for {len(models_to_scrape)} models\")\n",
    "        \n",
    "        # Scrape detailed information for each model\n",
    "        for model in tqdm(models_to_scrape, desc=\"Scraping model details\"):\n",
    "            model_id = model['id']\n",
    "            \n",
    "            try:\n",
    "                # Get basic info\n",
    "                model_data = {\n",
    "                    \"model_id\": model_id,\n",
    "                    \"name\": model_id.split('/')[-1] if '/' in model_id else model_id,\n",
    "                    \"author\": model.get('author', ''),\n",
    "                    \"downloads\": model.get('downloads', 0),\n",
    "                    \"likes\": model.get('likes', 0),\n",
    "                    \"tags\": model.get('tags', []),\n",
    "                    \"created_at\": model.get('createdAt', ''),\n",
    "                    \"last_modified\": model.get('lastModified', '')\n",
    "                }\n",
    "                \n",
    "                # Get detailed model info\n",
    "                model_details = self.get_model_details(model_id)\n",
    "                \n",
    "                # Extract parameter count\n",
    "                model_data[\"parameters\"] = self.extract_parameters(model_details, model_id)\n",
    "                \n",
    "                # Extract metrics\n",
    "                metrics = self.extract_metrics(model_details)\n",
    "                for key, value in metrics.items():\n",
    "                    model_data[f\"metric_{key}\"] = value\n",
    "                \n",
    "                self.models_data.append(model_data)\n",
    "                time.sleep(0.5)  # Be nice to the API\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {model_id}: {e}\")\n",
    "    \n",
    "    def save_to_csv(self, filename=\"huggingface_models.csv\"):\n",
    "        \"\"\"Save the scraped data to CSV\"\"\"\n",
    "        df = pd.DataFrame(self.models_data)\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Data saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "676cfe04-173a-4ef6-98f0-555026672410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install huggingface_hub requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "960ea168-bff3-4127-ab1e-31ca441a6423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 models for family gpt\n",
      "Found 20 models for family llama\n",
      "Found 20 models for family mistral\n",
      "Found 20 models for family falcon\n",
      "Found 20 models for family bert\n",
      "Found 20 models for family roberta\n",
      "Found 20 models for family vit\n",
      "Found 20 models for family clip\n",
      "Found 20 models for family resnet\n",
      "Found 20 models for family whisper\n",
      "Will scrape details for 50 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aaping model details:   0%|                            | 0/50 [00:00<?, ?it/s]\n",
      "\u001b[Aaping model details:   2%|▍                   | 1/50 [00:00<00:44,  1.10it/s]\n",
      "\u001b[Aaping model details:   4%|▊                   | 2/50 [00:01<00:43,  1.12it/s]\n",
      "\u001b[Aaping model details:   6%|█▏                  | 3/50 [00:02<00:41,  1.15it/s]\n",
      "\u001b[Aaping model details:   8%|█▌                  | 4/50 [00:03<00:40,  1.14it/s]\n",
      "\u001b[Aaping model details:  10%|██                  | 5/50 [00:04<00:45,  1.02s/it]\n",
      "\u001b[Aaping model details:  12%|██▍                 | 6/50 [00:06<00:50,  1.14s/it]\n",
      "\u001b[Aaping model details:  14%|██▊                 | 7/50 [00:06<00:44,  1.03s/it]\n",
      "\u001b[Aaping model details:  16%|███▏                | 8/50 [00:07<00:41,  1.01it/s]\n",
      "\u001b[Aaping model details:  18%|███▌                | 9/50 [00:08<00:39,  1.05it/s]\n",
      "\u001b[Aaping model details:  20%|███▊               | 10/50 [00:09<00:36,  1.09it/s]\n",
      "\u001b[Aaping model details:  22%|████▏              | 11/50 [00:10<00:35,  1.11it/s]\n",
      "\u001b[Aaping model details:  24%|████▌              | 12/50 [00:11<00:33,  1.13it/s]\n",
      "\u001b[Aaping model details:  26%|████▉              | 13/50 [00:12<00:33,  1.11it/s]\n",
      "\u001b[Aaping model details:  28%|█████▎             | 14/50 [00:13<00:31,  1.13it/s]\n",
      "\u001b[Aaping model details:  30%|█████▋             | 15/50 [00:13<00:29,  1.17it/s]\n",
      "\u001b[Aaping model details:  32%|██████             | 16/50 [00:14<00:28,  1.19it/s]\n",
      "\u001b[Aaping model details:  34%|██████▍            | 17/50 [00:16<00:42,  1.28s/it]\n",
      "\u001b[Aaping model details:  36%|██████▊            | 18/50 [00:17<00:36,  1.15s/it]\n",
      "\u001b[Aaping model details:  38%|███████▏           | 19/50 [00:18<00:33,  1.07s/it]\n",
      "\u001b[Aaping model details:  40%|███████▌           | 20/50 [00:19<00:30,  1.02s/it]\n",
      "\u001b[Aaping model details:  42%|███████▉           | 21/50 [00:20<00:29,  1.01s/it]\n",
      "\u001b[Aaping model details:  44%|████████▎          | 22/50 [00:21<00:27,  1.01it/s]\n",
      "\u001b[Aaping model details:  46%|████████▋          | 23/50 [00:22<00:26,  1.00it/s]\n",
      "\u001b[Aaping model details:  48%|█████████          | 24/50 [00:23<00:24,  1.05it/s]\n",
      "\u001b[Aaping model details:  50%|█████████▌         | 25/50 [00:24<00:24,  1.01it/s]\n",
      "\u001b[Aaping model details:  52%|█████████▉         | 26/50 [00:25<00:25,  1.06s/it]\n",
      "\u001b[Aaping model details:  54%|██████████▎        | 27/50 [00:26<00:23,  1.01s/it]\n",
      "\u001b[Aaping model details:  56%|██████████▋        | 28/50 [00:27<00:24,  1.12s/it]\n",
      "\u001b[Aaping model details:  58%|███████████        | 29/50 [00:28<00:22,  1.08s/it]\n",
      "\u001b[Aaping model details:  60%|███████████▍       | 30/50 [00:29<00:20,  1.03s/it]\n",
      "\u001b[Aaping model details:  62%|███████████▊       | 31/50 [00:30<00:19,  1.03s/it]\n",
      "\u001b[Aaping model details:  64%|████████████▏      | 32/50 [00:31<00:17,  1.02it/s]\n",
      "\u001b[Aaping model details:  66%|████████████▌      | 33/50 [00:32<00:17,  1.01s/it]\n",
      "\u001b[Aaping model details:  68%|████████████▉      | 34/50 [00:33<00:15,  1.03it/s]\n",
      "\u001b[Aaping model details:  70%|█████████████▎     | 35/50 [00:34<00:14,  1.03it/s]\n",
      "\u001b[Aaping model details:  72%|█████████████▋     | 36/50 [00:35<00:13,  1.06it/s]\n",
      "\u001b[Aaping model details:  74%|██████████████     | 37/50 [00:36<00:11,  1.11it/s]\n",
      "\u001b[Aaping model details:  76%|██████████████▍    | 38/50 [00:37<00:10,  1.10it/s]\n",
      "\u001b[Aaping model details:  78%|██████████████▊    | 39/50 [00:38<00:10,  1.07it/s]\n",
      "\u001b[Aaping model details:  80%|███████████████▏   | 40/50 [00:40<00:12,  1.25s/it]\n",
      "\u001b[Aaping model details:  82%|███████████████▌   | 41/50 [00:41<00:10,  1.14s/it]\n",
      "\u001b[Aaping model details:  84%|███████████████▉   | 42/50 [00:42<00:08,  1.06s/it]\n",
      "\u001b[Aaping model details:  86%|████████████████▎  | 43/50 [00:42<00:07,  1.00s/it]\n",
      "\u001b[Aaping model details:  88%|████████████████▋  | 44/50 [00:43<00:05,  1.01it/s]\n",
      "\u001b[Aaping model details:  90%|█████████████████  | 45/50 [00:44<00:04,  1.03it/s]\n",
      "\u001b[Aaping model details:  92%|█████████████████▍ | 46/50 [00:45<00:03,  1.07it/s]\n",
      "\u001b[Aaping model details:  94%|█████████████████▊ | 47/50 [00:46<00:02,  1.08it/s]\n",
      "\u001b[Aaping model details:  96%|██████████████████▏| 48/50 [00:47<00:01,  1.10it/s]\n",
      "\u001b[Aaping model details:  98%|██████████████████▌| 49/50 [00:48<00:00,  1.13it/s]\n",
      "Scraping model details: 100%|███████████████████| 50/50 [00:49<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to huggingface_models.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create scraper instance\n",
    "scraper = HuggingFaceScraper()\n",
    "\n",
    "# Run the scraper (adjust max_models as needed)\n",
    "scraper.scrape_models(max_models=50)\n",
    "\n",
    "# Save results to CSV\n",
    "scraper.save_to_csv(\"huggingface_models.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073ecb91-4f80-4e99-a930-c6c88a21b0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
